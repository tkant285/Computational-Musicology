---
title: "index.Rmd"
author: "Trisha Kant"
date: "2023-02-15"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r}
library(tidyverse)
library(ggplot2)
library(plotly)
library(spotifyr)
library(compmus)
```

### WEEK 10 HW: Comparing Techno vs Electro Jazz [Chordogram/Keygram]  
```{r}
techno_jazz <-
  get_playlist_audio_features("", "5pWntw7hWEgh6joLmH3LmN") |>
  slice(1:30) |>
  add_audio_analysis()
electro_jazz <-
  get_playlist_audio_features("", "4fZIq4iZ72kiVlP4YJ48Ec") |>
  slice(1:30) |>
  add_audio_analysis()
jazz_types <-
  techno_jazz |>
  mutate(genre = "Techno Jazz") |>
  bind_rows(electro_jazz |> mutate(genre = "Electro Jazz"))

jazz_types |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
This visual depicts a low-level audio analysis chordogram for the comparison of 2 playlists of techno jazz and electronic jazz. The difference between these genres of jazz is that techno follows a 4x4 beat, whereas electro follows a 3x2 or sometimes a 3x4 beat. This difference is observable in the graphic, as you can see all the techno songs fall along a similar mean tempo, with varying standard deviations. However, since electro songs follow a more miscellanous rhythm, their mean tempos are more scattered across the graph accordingly. The length of the song doesn't seem to impact the results too much as there seems to be an even distribution between the longer and shorter songs in regards to their mean tempo. Looking at this graph, I would put electro jazz as an outlier of my corpus since the results from this playlist are more arbitrary to analyze as compared to techno jazz, which has more cohesive results. 

### WEEK 9 HW: 1) CEPSTROGRAM
```{r}
craziest <-
  get_tidy_audio_analysis("52o1gnWz14YMxlZYAYycTe") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  )

craziest |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() +
  ggtitle("Cepstrogram of Science Fiction")
```

***
I chose to analyze a piece of jazz named 'Science Fiction'. This may be one of the most cacophonous pieces of music I have ever listened to. One can discern where it gets its jazz label from, but that's probably the extent of the relation to the genre. There is no distinct tempo/rhythm/beat, and the flurry of instrumentals combined with randomly placed vocals gives the graph its coloring. The song tends to stay in the same couple of pitches, which we see are C1, C3, and C6. It made the most sense to analyze this song in terms of bars as compared to beats/tatums/sections, since there is no distinct patterns throughout the song. The artist uses an extremely wide variety of different acoustics in this song -- even including the noises of a crying baby! Additionally, using a euclidean method of distance helps us best display the range of sound this song runs to, given its larger range as compared to other distance formulas.


### WEEK 9 HW: 2) SELF-SIMILARITY MATRIX: Examining Chroma + Timbre Features
```{r}
craziest |>
  compmus_self_similarity(timbre, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (sec)", y = "Time (sec)") + 
  ggtitle("Self-Similarity Matrix: Timbre in Science Fiction")
```

***
The self-similarity matrix allows us to see exactly how chaotic this piece of music is. There is truly no distinct rhythm throughout the song, and only a few bars where some sort of tempo can be distinguished, around the 210th and 280th seconds; the very tailend of the song, with a mere 20 seconds to spare (when the song begins to finally slow and calm down). 

### [INTRODUCTION] An In-Depth Description of the Jazzical Corpus I Will Utilize Throughout This Course

```{r}

```
***

My corpus focuses on how has jazz evolved over the eras, starting from the 1920s. I picked this corpus because the origin of the genre and the multitude of strong cultural backgrounds tied to it piqued my interest. It will be interesting to explore the differences in the genre throughout the different ages of jazz, as well as how the abundance of sub-genres began to sprout from said eras as groups of comparison. I also like how there are a variety of instruments used in jazz, and different combinations of different instruments produce unique sounds. I expect some differences to be found in how the culture of the given time period, as well as sub-genre influence, affects the overall sound of that era in terms of tempo and chords. I expect for there to be an underlying similar rhythm maintained. There is a ridiculous amount of diversity in the world of jazz music on Spotify. I will have to find the specific sound of each decade and compare those, otherwise it is risky to get lost in the sea of sub-genres that exist within the genre. I have begun doing this by creating playlists that separate the eras of jazz -- I have started widely with "new" and "old" jazz (as such the playlists are named), and will continue to narrow down the scope of these playlists and refine the content such that they fill different niches of the genre.

### [VISUALIZATION] #1: NEW Jazz Outlier Song
```{r}
nordic <-
  get_tidy_audio_analysis("64SgPjq2ewcWwevrQO9wNQ") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

nordic |>
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  ggtitle("Chromagraph of Nordic 'Jazz' Song") +
  theme_minimal() +
  scale_fill_viridis_c()
```

### Lab 9: Experimenting with Cepstrograms
```{r}
noBigThing <-
  get_tidy_audio_analysis("5FIuy1qgSfOENMDKHjsAsb") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  )

noBigThing |>
  compmus_self_similarity(timbre, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```


### [DISCUSSION]

***

This page discusses the analysis of the visualization seen on the second tab. I chose to create a visualization of this piece of music, as it is an outlier amongst my group of newer jazz songs. I chose to use the manhattan measure in my graph as it provides a more in-depth look at the scale of the unusual timbre observed in this song. This artist comes from a Nordic background, so she uses different types of throatal acoustics, producing interesting sounding vocal noises (some call it singing, some don't). Additionally, while this artist uses some standard instruments in her music, she also uses some unusual instruments such as a seed shaker, a waterphone, and even scraping a rock against another rocky surface. This unusual assortment of instruments is also part of the explanation as to why the chromagraph exhibits a less popular skew of timbre across the time frame of the song. More usual jazz songs have a heavier spread of timbre starting at the 0 second mark, yet this song doesn't begin to pick up on the acoustics until around the 50 second mark.
